{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../data/news_dataset_lite.json'\n",
    "output_data = '../data/processed_data_lite.json'\n",
    "output_vocab = '../data/vocab_lite.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số từ trong trường \"content\": 20821\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Đọc dữ liệu từ file JSON\n",
    "with open('../data/vocab_lite.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Trích xuất trường \"content\"\n",
    "# contents = [item['content'] for item in data if 'content' in item]\n",
    "\n",
    "# Tính tổng số từ trong trường \"content\"\n",
    "# total_words = sum(len(content.split()) for content in contents)\n",
    "\n",
    "# In ra kết quả\n",
    "print(f'Tổng số từ trong trường \"content\": {len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)  # Loại bỏ URL\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \" \", text)  # Loại bỏ nội dung trong ngoặc\n",
    "    text = re.sub(r\"\\b\\w*\\d\\w*\\b\", \" \", text)  # Loại bỏ số\n",
    "    texts = re.split(r'(?<=[.,!?;])\\s+', text.strip())  # Tách câu\n",
    "    texts = [re.sub(r\"[^\\w\\s]\", \" \", text) for text in texts]  # Loại bỏ ký tự đặc biệt\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm xử lý tách từ cho một item\n",
    "def process_item(item):\n",
    "    # Tách từ cho từng dòng trong 'contents'\n",
    "    tokenized_contents = [ViTokenizer.tokenize(it) for it in item['contents']]\n",
    "    item['contents'] = []\n",
    "\n",
    "    for tokenized_line in tokenized_contents:\n",
    "        # Gán nhãn từ loại\n",
    "        words, pos_tags = ViPosTagger.postagging(tokenized_line)\n",
    "\n",
    "        # Loại bỏ các từ loại 'Np' (danh từ riêng)\n",
    "        filtered_words = [word for word, pos in zip(words, pos_tags) if pos != 'Np']\n",
    "        item['contents'].append(\" \".join(filtered_words))  # Gộp lại thành câu\n",
    "\n",
    "    return item\n",
    "\n",
    "# Hàm chính để xử lý song song\n",
    "def parallel_processing(data):\n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap(process_item, data), total=len(data)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5527/5527 [00:00<00:00, 1692605.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Lấy những thông tin cần thiết\n",
    "filtered_data = [\n",
    "    {\n",
    "        \"id\": item[\"id\"],\n",
    "        \"content\": item[\"content\"]\n",
    "    }\n",
    "    for item in tqdm(data)\n",
    "]\n",
    "data = filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5527/5527 [00:01<00:00, 4923.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loại bỏ nội dung không cần thiết\n",
    "for item in tqdm(data):\n",
    "    item[\"contents\"] = clean_text(item[\"content\"])\n",
    "    del item[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5527/5527 [00:07<00:00, 746.89it/s]\n"
     ]
    }
   ],
   "source": [
    "data = parallel_processing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5527/5527 [00:00<00:00, 66812.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Chuyển thành chữ thường\n",
    "for item in tqdm(data):\n",
    "    item[\"contents\"] = [it.lower() for it in item[\"contents\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2964/2964 [00:00<00:00, 455198.16it/s]\n",
      "20821it [00:00, 3383163.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Xoá các item không có nội dung hoặc nội dung rỗng\n",
    "data = [item for item in data if item[\"contents\"] and all([it for it in item[\"contents\"]])]\n",
    "\n",
    "# Gộp tất cả các từ lại\n",
    "all_words = \" \".join([it for item in tqdm(data) for it in item[\"contents\"]]).split()\n",
    "all_words = [word.strip() for word in all_words]\n",
    "\n",
    "# Đếm tần suất xuất hiện của các từ\n",
    "vocab = Counter(all_words)\n",
    "\n",
    "# Tạo từ điển từ vựng (word2idx)\n",
    "word_to_idx = {word: idx for idx, word in tqdm(enumerate(vocab.keys()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu dữ liệu\n",
    "with open(output_data, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(output_vocab, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(word_to_idx, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
